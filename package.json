{
  "name": "llm-interrogator",
  "version": "1.0.0",
  "description": "LLM Interrogator - Extract concepts from LLM training data",
  "workspaces": ["frontend"],
  "scripts": {
    "setup": "python3 -m venv venv && ./venv/bin/pip install -r requirements.txt && npm install && test -f .env || cp .env.example .env",
    "start": "npm run build && concurrently \"npm run backend\" \"npm run open\"",
    "dev": "concurrently \"npm run backend\" \"npm run frontend:dev\" \"sleep 2 && npm run open\"",
    "backend": "./venv/bin/python app.py",
    "frontend:dev": "npm run dev -w frontend",
    "build": "npm run build -w frontend",
    "open": "sleep 1 && (open http://localhost:5001 || xdg-open http://localhost:5001 || start http://localhost:5001)"
  },
  "devDependencies": {
    "concurrently": "^8.2.0"
  }
}
